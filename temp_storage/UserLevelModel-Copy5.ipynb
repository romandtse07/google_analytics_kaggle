{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transaction Level Models\n",
    "\n",
    "While it was expected that aggregation of features in a somewhat arbitrary manner would result in the loss of information, it was not expected that such an approach would not be able to beat the baseline score of guessing only zeros.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_9.4.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "import catboost as cb\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sqlalchemy.create_engine('postgresql://romandtse:duckthewut@localhost:5432/training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickles/field_dict.pkl', 'rb') as f:\n",
    "    field_dict = pickle.load(f)\n",
    "    \n",
    "with open('../pickles/useless_fields.pkl', 'rb') as f:\n",
    "    useless_fields = pickle.load(f)\n",
    "\n",
    "with open('../pickles/adwordsClickInfo_keys.pkl', 'rb') as f:\n",
    "    adwordsClickInfo_keys = pickle.load(f)\n",
    "    \n",
    "with open('../pickles/channel_groups.pkl', 'rb') as f:\n",
    "    channel_groups = pickle.load(f)\n",
    "    \n",
    "with open('../pickles/field_vals.pkl', 'rb') as f:\n",
    "    field_vals = pickle.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "query = \"\"\"\n",
    "SELECT fullVisitorId\n",
    "FROM train_data\n",
    "GROUP BY fullVisitorId\n",
    "HAVING SUM(CAST(totals ->> 'transactionRevenue' AS numeric)) > 0\n",
    "\"\"\"\n",
    "\n",
    "customers = pd.read_sql_query(query, engine)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('../pickles/train_customer_ids.pkl', 'wb') as f:\n",
    "    pickle.dump(customers, f)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "query = \"\"\"\n",
    "SELECT fullVisitorId\n",
    "FROM train_data\n",
    "GROUP BY fullVisitorId\n",
    "HAVING SUM(CAST(totals ->> 'transactionRevenue' AS numeric)) IS NULL\n",
    "\"\"\"\n",
    "\n",
    "lookers = pd.read_sql_query(query, engine)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open('./pickles/train_looker_ids.pkl', 'wb') as f:\n",
    "    pickle.dump(lookers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickles/train_customer_ids.pkl', 'rb') as f:\n",
    "    train_customer_ids = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is the question of scaling the revenue.  By coincidence, or maybe by design, the target is actually scaled by the natural log.  When we fit a regressor, there will necessarily be negative values.  Since we will send these values through another model, we should consider scaling everything by the natural log here; the argument is not that we pretend a single session should imitate a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def revTemplate(key, name, num_type = 'FLOAT'):\n",
    "    return f\"\"\"COALESCE(CAST({key} ->> '{name}' AS {num_type}), 0)/10^6 AS {name}\"\"\"\n",
    "\n",
    "def jnumTemplate(key, name, num_type = 'INT'):\n",
    "    return f\"\"\"COALESCE(CAST({key} ->> '{name}' AS {num_type}), 0) AS {name}\"\"\"\n",
    "\n",
    "def numTemplate(name):\n",
    "    return f\"\"\"COALESCE({name}, 0) AS {name}\"\"\"\n",
    "\n",
    "def jstrTemplate(key, name):\n",
    "    return f\"{key} ->> '{name}' AS {name}\"\n",
    "\n",
    "def strTemplate(name):\n",
    "    return f\"{name}\"\n",
    "\n",
    "def adwordsTemplate(name):\n",
    "    return f\"CAST(trafficSource ->> 'adwordsClickInfo' AS JSONB) ->> '{name}' AS {name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getQuery(dataset = 'train'):\n",
    "    numeric_cols = ['visitNumber', 'newVisits', 'bounces', 'pageviews', 'visits', 'hits', 'transactionRevenue']\n",
    "    if dataset != 'train':\n",
    "        numeric_cols.pop()\n",
    "    selects = []\n",
    "    for cat, subcats in field_dict.items():\n",
    "        for subcat in subcats:\n",
    "            if subcat not in useless_fields[dataset]:\n",
    "                if subcat == 'transactionRevenue':\n",
    "                    selects.append(revTemplate(cat, subcat, 'NUMERIC'))\n",
    "                elif subcat in numeric_cols:\n",
    "                    selects.append(jnumTemplate(cat, subcat))\n",
    "                elif subcat == 'adwordsClickInfo':\n",
    "                    for key in adwordsClickInfo_keys:\n",
    "                        selects.append(adwordsTemplate(key))\n",
    "                else:\n",
    "                    selects.append(jstrTemplate(cat, subcat))\n",
    "    selects.extend([numTemplate('visitNumber'), \n",
    "                    strTemplate('channelGrouping'),\n",
    "                    strTemplate('fullVisitorId'),\n",
    "                    numTemplate('visitStartTime'),\n",
    "                   ])\n",
    "    return ', '.join(selects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "qstring = getQuery()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickles/top_order.pkl', 'rb') as f:\n",
    "    top_order = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note to self: if you don't change the ids list, you will lose a lot of ids.\n",
    "#you will train on less data than you think, but you won't inflate the score at least by having those you excluded.\n",
    "def getUserData(user_list):\n",
    "    users = \"\\', \\'\".join(user_list)\n",
    "    query = f\"\"\"\n",
    "    SELECT {qstring}\n",
    "    FROM train_data\n",
    "    WHERE fullVisitorId IN (\\'{users}\\')\n",
    "    \"\"\"\n",
    "\n",
    "    return pd.read_sql_query(query, engine, parse_dates=['visitstarttime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickles/objects.pkl', 'rb') as f:\n",
    "    objects = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By introducing all possible values of fields ahead of time for dummying, independent of whether they show up in the training set or not, we fail to simulate the fact that we have no idea whether we have captured all the features.  The categories included here, though are fairly set in stone; there probably are not many sub continents that have yet to appear in the store's history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjustCols(df, drop_ids = True, ignore_bounce = True):\n",
    "    back_looking = ['bounces', 'hits', 'newvisits', 'pageviews']\n",
    "    \n",
    "    df = df.sort_values(['fullvisitorid','visitstarttime'])\n",
    "    #turns out the for loop checks col_order dynamically, temporary list needed to avoid infinite loop\n",
    "    for col in back_looking:\n",
    "        df[f'{col}last'] = df.groupby('fullvisitorid')[col].shift(1)\n",
    "        df[f'{col}two'] = df.groupby('fullvisitorid')[col].shift(2)\n",
    "    df['sincelast'] = df.groupby('fullvisitorid').visitstarttime.diff().map(lambda x: x.days + x.seconds/86400)\n",
    "    df['sincetwo'] = df.groupby('fullvisitorid').visitstarttime.diff(2).map(lambda x: x.days + x.seconds/86400)\n",
    "    df['hour'] = df.visitstarttime.map(lambda x: x.hour)\n",
    "    df['weekday'] = df.visitstarttime.map(lambda x: x.dayofweek)\n",
    "    df['month'] = df.visitstarttime.map(lambda x: x.month)\n",
    "    \n",
    "    if drop_ids:\n",
    "        df = df.drop('fullvisitorid', axis=1)\n",
    "        \n",
    "    if ignore_bounce:\n",
    "        df = df.query('bounces==0')\n",
    " \n",
    "    return df.drop('visitstarttime', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickles/train_customer_ids.pkl', 'rb') as f:\n",
    "    train_customer_ids = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../pickles/train_looker_ids.pkl', 'rb') as f:\n",
    "    train_looker_ids = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle now so we can just iterate through lists\n",
    "from random import shuffle\n",
    "\n",
    "def stratifiedIdSplit(test_size=0.5):\n",
    "    customer_size = int(len(train_customer_ids)*test_size)\n",
    "    looker_size = int(len(train_looker_ids)*test_size)\n",
    "    \n",
    "    test_customers = list(np.random.choice(train_customer_ids.T.values[0], replace=False, size=customer_size))\n",
    "    test_lookers = list(np.random.choice(train_looker_ids.T.values[0], replace=False, size=looker_size))\n",
    "    \n",
    "    train_customers = list(set(train_customer_ids.T.values[0]).difference(set(test_customers)))\n",
    "    train_lookers = list(set(train_looker_ids.T.values[0]).difference(set(test_lookers)))\n",
    "    \n",
    "    test_customers.extend(test_lookers)\n",
    "    train_customers.extend(train_lookers)\n",
    "    \n",
    "    shuffle(test_customers)\n",
    "    shuffle(train_customers)\n",
    "    \n",
    "    return train_customers, test_customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, test_ids = stratifiedIdSplit(0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we can hope a machine can learn what is unique about this outlier, the fact is that there is no one else like this user.  In our ensemble later, considering it is a system of gradient boosted trees, there is a very good chance that one of the forests will be awful at guessing because it was fit to minimize the error it would get from this outlier point.  With all its activity, though, perhaps the behavior could still fall in line with the other points of data.  For the fear of overfitting to this point, and because our validation can tell us nothing about how well it does on similar outliers (because there are none like it), we remove it from our model for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_ids.remove(top_order.iloc[0,0])\n",
    "except:\n",
    "    test_ids.remove(top_order.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['devicecategory', 'ismobile', 'browser', 'operatingsystem', 'city',\n",
       "       'continent', 'country', 'metro', 'networkdomain', 'region',\n",
       "       'subcontinent', 'bounces', 'hits', 'newvisits', 'pageviews',\n",
       "       'transactionrevenue', 'adcontent', 'adnetworktype',\n",
       "       'criteriaparameters', 'gclid', 'isvideoad', 'page', 'slot',\n",
       "       'targetingcriteria', 'campaign', 'campaigncode', 'istruedirect',\n",
       "       'keyword', 'medium', 'referralpath', 'source', 'visitnumber',\n",
       "       'channelgrouping', 'fullvisitorid', 'visitstarttime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getUserData([test_ids[0]]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createChunk(ids_list, size, drop_ids = True, ignore_bounce=True):\n",
    "    new_size = len(ids_list)\n",
    "    if  new_size > size:\n",
    "        new_size = size\n",
    "    someppl = ids_list\n",
    "    shuffle(someppl)\n",
    "    someppl = someppl[:new_size]\n",
    "    chunk = getUserData(someppl)\n",
    "    chunk = adjustCols(chunk, drop_ids, ignore_bounce)\n",
    "    \n",
    "    return chunk.fillna(0), ids_list[new_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_df = adjustCols(getUserData([top_order.iloc[0][0]])).drop('transactionrevenue', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_vals = adjustCols(getUserData([top_order.iloc[0][0]])).transactionrevenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feets = np.where(trial_df.dtypes == object)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['devicecategory', 'ismobile', 'browser', 'operatingsystem', 'city',\n",
       "       'continent', 'country', 'metro', 'networkdomain', 'region',\n",
       "       'subcontinent', 'adcontent', 'adnetworktype', 'criteriaparameters',\n",
       "       'gclid', 'isvideoad', 'page', 'slot', 'targetingcriteria', 'campaign',\n",
       "       'campaigncode', 'istruedirect', 'keyword', 'medium', 'referralpath',\n",
       "       'source', 'channelgrouping'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_df.columns[cat_feets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of training a set of trees and losing most of the trees, let's make an ensemble.  We can blend it and fit to the actual target with a single ensemble in two stages; we fit by session while still preventing user leakage before using these to predict the sum of all sessions and fitting on a separate validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 28.5226220\ttotal: 186ms\tremaining: 3m 5s\n",
      "250:\tlearn: 19.2779875\ttotal: 47.7s\tremaining: 2m 22s\n",
      "500:\tlearn: 17.5186773\ttotal: 1m 33s\tremaining: 1m 33s\n",
      "750:\tlearn: 16.3650917\ttotal: 2m 19s\tremaining: 46.4s\n",
      "999:\tlearn: 15.6677882\ttotal: 3m 5s\tremaining: 0us\n",
      "0:\tlearn: 23.0670469\ttotal: 213ms\tremaining: 3m 33s\n",
      "250:\tlearn: 16.2089718\ttotal: 46.9s\tremaining: 2m 19s\n",
      "500:\tlearn: 14.8258192\ttotal: 1m 34s\tremaining: 1m 33s\n",
      "750:\tlearn: 14.0626531\ttotal: 2m 21s\tremaining: 47s\n",
      "999:\tlearn: 13.4558894\ttotal: 3m 8s\tremaining: 0us\n",
      "0:\tlearn: 22.5475749\ttotal: 203ms\tremaining: 3m 22s\n",
      "250:\tlearn: 16.6372347\ttotal: 45.9s\tremaining: 2m 16s\n",
      "500:\tlearn: 15.2279871\ttotal: 1m 31s\tremaining: 1m 31s\n",
      "750:\tlearn: 14.0748189\ttotal: 2m 17s\tremaining: 45.6s\n",
      "999:\tlearn: 13.5086973\ttotal: 3m 3s\tremaining: 0us\n",
      "0:\tlearn: 21.6369849\ttotal: 178ms\tremaining: 2m 57s\n",
      "250:\tlearn: 17.0823143\ttotal: 46.3s\tremaining: 2m 18s\n",
      "500:\tlearn: 15.8162432\ttotal: 1m 32s\tremaining: 1m 32s\n",
      "750:\tlearn: 14.7308049\ttotal: 2m 18s\tremaining: 46.1s\n",
      "999:\tlearn: 13.8100865\ttotal: 3m 4s\tremaining: 0us\n",
      "0:\tlearn: 64.7715310\ttotal: 188ms\tremaining: 3m 8s\n",
      "250:\tlearn: 48.8744042\ttotal: 49.3s\tremaining: 2m 27s\n",
      "500:\tlearn: 43.8687633\ttotal: 1m 37s\tremaining: 1m 36s\n",
      "750:\tlearn: 40.8879424\ttotal: 2m 25s\tremaining: 48.2s\n",
      "999:\tlearn: 37.7871738\ttotal: 3m 11s\tremaining: 0us\n",
      "0:\tlearn: 24.2517952\ttotal: 201ms\tremaining: 3m 20s\n",
      "250:\tlearn: 14.7102541\ttotal: 46.4s\tremaining: 2m 18s\n",
      "500:\tlearn: 12.5228840\ttotal: 1m 32s\tremaining: 1m 32s\n",
      "750:\tlearn: 11.5917209\ttotal: 2m 19s\tremaining: 46.3s\n",
      "999:\tlearn: 10.9652914\ttotal: 3m 19s\tremaining: 0us\n",
      "0:\tlearn: 26.4307295\ttotal: 280ms\tremaining: 4m 39s\n",
      "250:\tlearn: 18.5363384\ttotal: 50.5s\tremaining: 2m 30s\n",
      "500:\tlearn: 16.9399520\ttotal: 1m 41s\tremaining: 1m 40s\n",
      "750:\tlearn: 15.7043240\ttotal: 2m 33s\tremaining: 50.9s\n",
      "999:\tlearn: 15.1451060\ttotal: 3m 23s\tremaining: 0us\n",
      "0:\tlearn: 57.1738356\ttotal: 92.4ms\tremaining: 1m 32s\n",
      "250:\tlearn: 48.6205153\ttotal: 27.8s\tremaining: 1m 22s\n",
      "500:\tlearn: 46.5601616\ttotal: 55.3s\tremaining: 55.1s\n",
      "750:\tlearn: 44.3163889\ttotal: 1m 24s\tremaining: 27.9s\n",
      "999:\tlearn: 42.7846099\ttotal: 1m 52s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "id_holder = train_ids\n",
    "fold = 13\n",
    "holdouts = 4\n",
    "fold_size = len(id_holder)//fold\n",
    "\n",
    "models = []\n",
    "first_ids = id_holder[:fold_size].copy()\n",
    "\n",
    "\n",
    "def trainCB(train_set, eval_pool, model_list):\n",
    "    model_list.append(cb.CatBoostRegressor(iterations = 1000,\n",
    "                                           learning_rate  = 5,\n",
    "                                           l2_leaf_reg = 100,\n",
    "                                           cat_features = cat_feets,\n",
    "                                           depth = 5,\n",
    "                                           verbose = True))\n",
    "    model_list[-1].fit(X = train_set.drop('transactionrevenue', axis=1),\n",
    "                       y = train_set.transactionrevenue,\n",
    "                       #use_best_model = True, \n",
    "                       #eval_set = eval_pool, \n",
    "                       #early_stopping_rounds = 10, \n",
    "                       metric_period = 250)\n",
    "\n",
    "eval_chunk, id_holder = createChunk(id_holder, fold_size, ignore_bounce=False)\n",
    "eval_chunk = cb.Pool(eval_chunk.drop('transactionrevenue', axis=1), \n",
    "                 eval_chunk.transactionrevenue, \n",
    "                 cat_features=cat_feets)\n",
    "chunk, id_holder = createChunk(id_holder, fold_size, ignore_bounce=False)\n",
    "trainCB(chunk, eval_chunk, models)\n",
    "\n",
    "\n",
    "for n in range(fold - holdouts - 2):\n",
    "    eval_chunk = chunk\n",
    "    eval_chunk = cb.Pool(eval_chunk.drop('transactionrevenue', axis=1), \n",
    "                     eval_chunk.transactionrevenue, \n",
    "                     cat_features=cat_feets)\n",
    "    if n < (fold - holdouts - 3):\n",
    "        chunk, id_holder = createChunk(id_holder, fold_size, ignore_bounce = False)\n",
    "    else:\n",
    "        chunk = createChunk(first_ids, fold_size)[0]\n",
    "    trainCB(chunk, eval_chunk, models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the arbitrary fold size of 8, we still get over sixty-two thousand users, and expect a good number of users to be paying customers.  We reserve 3 of these folds for validation and predicting the log of the sums.  We will also use the previous fold for validation, mostly to save space and time to be honest, though the first and last rounds must be treated separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a L2 coefficient of 100, trees tend to stop around 100 iterations.  At a coefficient of 1, they stop $O(10)$ iterations, with the RMSE still increasing only 1 unit by the end.  At 1000, the training runs for more iterations, but the gains are just as modest.  There is still the question of whether it is better to let the ensemble components overfit, but we might run into the problem we usually do with random forests.  At this rate, though, the system will do not much better than a small collection of independent decision trees.  We'll go ahead and try anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "del chunk, eval_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/cb_overfit_stage1.pkl', 'wb') as f:\n",
    "    pickle.dump(models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = createChunk(id_holder, len(id_holder), drop_ids=False, ignore_bounce=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_x = val_df.drop('transactionrevenue', axis=1)\n",
    "val_y = val_df[['fullvisitorid', 'transactionrevenue']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could inject zeros here, but catboost doesn't like predicting on series objects for some reason, and transforming them into dataframes and transposing those seems to take longer I think.  Should time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 16s, sys: 3.6 s, total: 2min 19s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predicts = [model.predict(val_x) for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounces_index = np.where(val_x.columns == 'bounces')[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(models)):\n",
    "    val_x[f'predicted_{i}'] = predicts[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "kept_columns = ['fullvisitorid', 'pageviews', 'newvisits', 'visitnumber', 'bounces']\n",
    "col_mask = [column in kept_columns or 'predicted_' in column for column in val_x.columns.values]\n",
    "x = val_x.loc[:,col_mask].groupby('fullvisitorid').sum()\n",
    "x2 = val_x.loc[:,col_mask].groupby('fullvisitorid').std()\n",
    "#x3 = val_x.loc[:,col_mask].groupby('fullvisitorid').max()\n",
    "x = x.join(x2, lsuffix='_mean', rsuffix='_std')\n",
    "#x = x.join(x3, rsuffix='_max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just realized some of these will be negative.  We need to transform them with a function that runs from zero to infinity and accepts negative infinity to infinity, or else use a different model.  We try the former here.  Why not, headed down a bad way at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = val_y.groupby('fullvisitorid').sum().applymap(lambda x: np.log(10**6*x + 1)).loc[x.index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(len(x)*.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = cb.Pool(data = x.iloc[:split, :], label = y.iloc[:split, :])\n",
    "train_set = cb.Pool(data = x.iloc[split:, :], label = y.iloc[split:, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "censemble = cb.CatBoostRegressor(iterations = 3000,\n",
    "                                 learning_rate  = .03,\n",
    "                                 l2_leaf_reg = 100,\n",
    "                                 use_best_model = True,\n",
    "                                 depth = 4,\n",
    "                                 verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Overfitting detector is active, thus evaluation metric iscalculated on every iteration. 'metric_period' is ignored for evaluation metric.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.1109433\ttest: 2.0913975\tbest: 2.0913975 (0)\ttotal: 23ms\tremaining: 1m 8s\n",
      "20:\tlearn: 1.8636055\ttest: 1.8473563\tbest: 1.8473563 (20)\ttotal: 501ms\tremaining: 1m 11s\n",
      "40:\tlearn: 1.7516807\ttest: 1.7391473\tbest: 1.7391473 (40)\ttotal: 871ms\tremaining: 1m 2s\n",
      "60:\tlearn: 1.7014753\ttest: 1.6913214\tbest: 1.6913214 (60)\ttotal: 1.24s\tremaining: 59.9s\n",
      "80:\tlearn: 1.6767566\ttest: 1.6682762\tbest: 1.6682762 (80)\ttotal: 1.59s\tremaining: 57.3s\n",
      "100:\tlearn: 1.6641107\ttest: 1.6573460\tbest: 1.6573460 (100)\ttotal: 1.95s\tremaining: 55.9s\n",
      "120:\tlearn: 1.6567981\ttest: 1.6514157\tbest: 1.6514157 (120)\ttotal: 2.3s\tremaining: 54.7s\n",
      "140:\tlearn: 1.6519951\ttest: 1.6487142\tbest: 1.6487142 (140)\ttotal: 2.68s\tremaining: 54.3s\n",
      "160:\tlearn: 1.6484803\ttest: 1.6469983\tbest: 1.6469983 (160)\ttotal: 3.02s\tremaining: 53.2s\n",
      "180:\tlearn: 1.6460921\ttest: 1.6458916\tbest: 1.6458824 (179)\ttotal: 3.37s\tremaining: 52.5s\n",
      "200:\tlearn: 1.6440410\ttest: 1.6450608\tbest: 1.6450608 (200)\ttotal: 3.75s\tremaining: 52.3s\n",
      "220:\tlearn: 1.6421804\ttest: 1.6446029\tbest: 1.6446015 (219)\ttotal: 4.09s\tremaining: 51.5s\n",
      "240:\tlearn: 1.6406264\ttest: 1.6440249\tbest: 1.6440249 (240)\ttotal: 4.47s\tremaining: 51.2s\n",
      "260:\tlearn: 1.6389978\ttest: 1.6436414\tbest: 1.6436198 (258)\ttotal: 4.83s\tremaining: 50.6s\n",
      "280:\tlearn: 1.6374616\ttest: 1.6435267\tbest: 1.6434966 (273)\ttotal: 5.16s\tremaining: 50s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 1.64349662\n",
      "bestIteration = 273\n",
      "\n",
      "Shrink model to first 274 iterations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x1a7ecb1828>"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "censemble.fit(train_set, eval_set=eval_set, use_best_model=True, early_stopping_rounds = 10, metric_period = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = createChunk(test_ids, len(test_ids), drop_ids=False, ignore_bounce=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
